---
title: "Getting started with BaiSOFR"
output: rmarkdown::github_document
vignette: >
  %\VignetteIndexEntry{Getting started with BaiSOFR}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  
bibliography: references.bib
link-citations: true
---
```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

The `BaiSOFR` package is a tool for fitting and interpreting Bayesian scalar-on-functional regression (SOFR) models, with the acronym `BaiSOFR` representing **Bayesian Adaptive and Interpretable Scalar-on-function regression**. The methods implemented in this package are derived from  ([@gao2022bayesian](https://arxiv.org/abs/2203.00784)). This document is designed to help new users get started with the main functionalities of `BaiSOFR` in R.

# Introduction 

Scalar-on-function regression (SOFR) is a type of regression where a scalar response variable is predicted based on one or several functional predictor(s). An example of SOFR model is as follows:

$$
y_i =  \mu + {\bf z_i}'{\bf\alpha} +  \sum_{j=1}^p\int_{\mathcal{T}_i} X_{j,i}( t)\beta_j (t)\ dt +\epsilon_i, \quad \epsilon_i \stackrel{iid}{\sim} \mathcal{N}(0, \sigma^2), \quad  i=1,...,n. \tag{1}
$$

In this model, the scalar response $y_i \in \mathbb{R}$ is linked to $p$ functional covariates $\{X_{j,i}: \mathcal{T}_i \rightarrow \mathbb{R}\}, \quad j=1,..,p$ and other scalar covariates $\bf z_i \in \mathbb{R}^{z_p}$. The compact domains $\mathcal{T}_i \subseteq \mathcal{T} \subset \mathbb{R}$ are subject-specific, and  $\mathcal{T}$ denotes the maximal domain over which the functional covariates $X_i$ may be observed. The integral term $\int_{\mathcal{T}_i} X_{j,i}(t)\beta_j (t)\ dt$ represents the cumulative effect of  $X_{j,i}$ over its domain $\mathcal{T}_i$, as captured by the unknown regression coefficient function $\beta_j$. The linear term $\bf z_i'\bf \alpha$ accounts for other scalar covariates that may influence the response $y_i$. 

A closely related model to the SOFR model is the distributed lag model (DLM) [@dziak2019scalar]. In the DLM, the integral in (1) is replaced with multiple regression terms that utilize $\{X_{j,i}(t)\}$ as covariates. However, unlike the SOFR model, the DLM requires the functional covariates $X_{j,i}$ to be observed at the same discrete points for all observations. This requirement could be challenging to meet in practical applications. Therefore, we prefer the usage of the SOFR model. 


This guide will walk you through two main functionalities of the `BaiSOFR` package using a simulated dataset:


1. **Bayesian Scalar-on-Function Regression**: One of the key objectives in fitting a SOFR model is to estimate and characterize the unknown regression coefficient functions ${\beta_j}$, as these functions illustrate the influence of functional covariates $X_{j,i}$ on the scalar response $y_i$. The `BaiSOFR` package enables users to fit a Bayesian SOFR model to their data using the `fitBASOFR()` function. This Bayesian SOFR model is specifically designed to **capture both smooth and abrupt variations** in the association function $\{\beta_j\}$. It provides full posterior uncertainty quantification while maintaining computational scalability, concerning both the sample size and the number of observation points for each functional covariate.

2. **Critical window selection for Bayesian SOFR Models**: The other main goal of fitting a SOFR model is to identify *critical windows*. These are regions within the domain $\mathcal{T}$ where $X_{j,i}$ are predictive of $y_i$, adjusted for other functional covariates and key confounding variables. Due to the high-dimensional and highly correlated nature of $X_{j,i}$, this task regarding SOFR interpretation is not trivial [@dziak2019scalar]. To improve interpretatbility, the `BaiSOFR` package offers **decision analysis** tools to extract more *interpretable* **locally constant point estimates** from **any** given Bayesian SOFR models using the `Interpret_SOFR()` function. 

We start from installing and loading the `BaiSOFR` package from
[GitHub](https://github.com/) with:

```{r}
# devtools::install_github("YunanGao/BaiSOFR")
library(BaiSOFR)
```


# Simulate the SOFR Data

In order to illustrate the usage of the `BaiSOFR` package, we will simulate data according to the SOFR model (1) using the `simulate_SOFR()` function. This data includes the response variable $y_i$, the functional covariates $\{X_{1,i}, X_{2,i}, X_{3,i}\}$, and the scalar covariates $\mathbf{z_i}$ (comprising 5 continuous covariates and 2 dummy covariates). We generate this data for $i=1,..., n=1000$ subjects:

```{r cache=TRUE}
set.seed(1234) # set random seed to ensure duplication of the results

# simulate the SOFR data
data = simulate_SOFR(n = 1000, # number of observations
                     p = 3, # number of functional covariates
                     SNR = 5, # Signal-to-noise ratio
                     num_z_continuous = 5, # number of continuous covariates in z
                     num_z_dummy = 2, # number of dummy covariates in z
                     beta_types = c('spiky','smooth','stepwise'), # the ground truth shape of beta
                     domain_X = c(0, 1), # maximal domain over which X are being observed
                     max_obs = 200, # maximal number of discrete points to observe X
                     subject_specific_domain = TRUE # whether to generate subject-specific domain
                     )

# View the simulated dataset
names(data)
```

Here:



- The `SNR` argument stands for signal-to-noise ratio, defined as $\text{sd}(y_i - \epsilon_i)/\text{sd}(y_i)$. Lower values generally make the modeling task more challenging.

- The `domain_X` and `max_obs` arguments define $\mathcal{T}$, and the discrete observation points for all $X$. With `domain_X = c(0, 1)` and `max_obs = 200` in our case, we have $\mathcal{T} = [0,1]$ and the discrete observation points are `seq(0,1,length.out=200)`. Setting `subject_specific_domain=TRUE` means that each $X_{j,i}$ is observed only on its subject-specific domain $[0, T_i]$, where $T_i \leq 1$.


- The `beta_types` argument lets you specify the ground truth shape of each $\beta_j$ function. Options include `'spiky'`, `'smooth'`, and `'stepwise'`. We can visualize the ground truth functions using the `plot_beta()` function:

```{r, fig.width=6, fig.height=4}

# Visualize the ground truth beta functions
plot_beta(beta_list = data$groundTruth$beta, x.grids = data$t.grid)
```

Given that we specified `beta_types = c('spiky','smooth','stepwise')` in the simulation code, the curves $\beta_1$, $\beta_2$, and $\beta_3$ correspond respectively to `'spiky'`, `'smooth'`, and `'stepwise'` in this plot.

# Bayesian SOFR Model

Once the data is prepared, we are interested in fitting the SOFR model to obtain posterior inference for $\{\beta_1,\beta_2, \beta_3, \mu, {\bf\alpha}, \sigma^2 | y, X, \bf z\}$. It's important to note that the true regression function's shape, such as $\beta_1(t)$ in the plot above, may either vary smoothly or exhibit abrupt changes. If we fail to accurately capture the shape of the true regression function, we can end up with biased estimates and poorly calibrated uncertainty quantification for $\beta_j$, as well as suboptimal predictions for $y$. To adapt to both smooth and abrupt changes in $\beta_j$, we developed our method. A brief technical overview of our approach is provided in the [Bayesian SOFR Model Overview](#BASOFR_overview) section, and its application is demonstrated in the [Fitting a Bayesian SOFR Model](#BASOFR_fit) section. 


## Bayesian SOFR Model Overview {#BASOFR_overview}

The Bayesian Scalar-on-Function Regression method serves as a useful tool for estimating and making inferences for $\beta_j$. Specifically designed to adapt to both smooth and rapid changes, the BASOFR model applies a B-spline basis expansion for each $\beta_j$ and employs a dynamic horseshoe prior [@kowal2019dynamic] on the second difference of the basis coefficients. This is defined for $j=1,...,p$ as:

\[
\begin{aligned}
\beta_j(t) &= \sum_{k=1}^{K_B} B_{j,k}^*\psi_k(t)\\
\Delta^2  B_{j,k}^* |\lambda_{j,k} &\stackrel{\text{indep}}{\sim} \mathcal{N}(0, \lambda_{j,k}^2), \quad \{\lambda_{j,k} \}\sim \text{DHS}
\end{aligned}
\]

Here, $\{\psi_k\}_{k=1}^{K_B}$ represents a collection of equally-spaced B-spline bases, and DHS refers to the dynamic horseshoe prior [@kowal2019dynamic]. This *local* and *adaptive* shrinkage prior is beneficial for function estimation as it encourages smoothness but can also capture rapid changes in $\beta_j$. As a result, the BASOFR method has shown substantially superior performance in scenarios that features both smooth and abrupt changes, as evidenced in various simulation studies in @gao2022bayesian. 

## Fiting a Bayesian SOFR Model {#BASOFR_fit}

The `fitBASOFR()` function serves as a straightforward tool to implement the proposed SOFR method. This function only requires the inputs `y`, `X`, `z`, and `t.grid` from the SOFR model (1). In our example, `t.grid` corresponds to `seq(0,1,length.out=200)`, which are the points at which the functions $\{X_{ji}\}_{j=1}^p$ are observed, and also the points where $\beta_j$ will be estimated. Since the `fitBASOFR()` function does not perform any scaling or centering for pre-processing the `z` values, we recommend users to conduct any necessary pre-processing, such as normalization or standardization, before passing them into the `z` argument. The function uses a Gibbs sampler to draw from the posterior distribution:

```{r cache=TRUE}
# Create the z-variables matrix
z = cbind(scale(data$Z_continuous), data$Z_dummy)

# Fit the BASOFR model
BASOFR_fit <- fitBASOFR(y = data$y, X = data$X, 
                        t.grid = data$t.grid,  # seq(0, 1, length.out=200)
                        z = z,
                        burnin = 1000,
                        S = 1000)
```



Upon completion, `fitBASOFR()` returns an object containing the posterior draws of $\{\beta_1,\beta_2, \beta_3, \mu, {\bf\alpha}, \sigma^2 | y, X, \bf z\}$, as well as the posterior expectations and credible intervals for $\{\beta_1,\beta_2, \beta_3\}$:

```{r}
names(BASOFR_fit)
```

To visualize the fit, we can use the `plot_BASOFR_fit()` function:

```{r  fig.width=6, fig.height=4}

# Obtain the ground truth beta
groundTruth.beta = matrix(unlist(data$groundTruth$beta), byrow=TRUE, nrow=3)

# Visualize the fit of Bayesian SOFR
plot_BASOFR_fit(BASOFR_fit = BASOFR_fit,
                groundTruth = groundTruth.beta # optional
                )
```

As shown from the plots, the proposed Bayesian SOFR model manages to effectively capture the ground truth, even when faced with the task of modelling complex shapes!



# Identifying Critical Windows for Bayesian SOFR Models

We employ a **decision analysis strategy** to identify critical windows and provide more interpretable model summaries for Bayesian SOFR models through the `Interpret_SOFR()` function.

For *any* Bayesian SOFR model $\mathcal{M}$, the `Interpret_SOFR()` function offers:

1. Optimal **locally constant** point estimates of the regression functions (with uncertainty quantification of their predictive accuracy) of different complexity (i.e. different numbers of changing points).

2. The **acceptable family** of the locally constant point estimates, which are *near-optimal* concerning predictive accuracy compared to the "best" locally constant estimator.

3. The **simplest acceptable family member** of the locally constant estimates, prioritizing simplicity while maintaining predictive accuracy.


For demonstration, we use the previously fitted Bayesian Adaptive SOFR model to illustrate the use of the `Interpret_SOFR()` function. This function requires only *sampling* from the posterior as well as the data observation:

```{r fig.width=5, fig.height=3.75, cache=TRUE}
BayesSOFR <- BASOFR_fit # It can be any Bayesian SOFR model, does not limit to our BASOFR model.

SOFR_Interpret <- Interpret_SOFR(# the posterior samples
                                 beta.post = BayesSOFR$beta.post, 
                                 Alpha.post = BayesSOFR$Alpha.post,
                                 intercept.post = BayesSOFR$intercept.post,
                                 sigma2.post = BayesSOFR$sigma.2.post,
                                 # the data observations
                                 y = data$y, 
                                 X = data$X, 
                                 z = z,
                                 t.grid = data$t.grid)
``` 

`Interpret_SOFR()` automatically generates two plots for each regression function $\beta_j$:

The first plot shows how the predictive performance varies across locally constant point estimates with different complexity, specifically relative (% change) to the "best" model (dashed grey vertical line). For each regression function, while the predictive performance generally improves as complexity increases, it is clear that several simpler models are highly competitive. This is observation holds particularly true when considering predictive uncertainty.

If we wish to select a single locally constant estimate, a compelling choice would be the simplest member in the acceptable family (solid grey vertical line). This choice represents the locally constant model with the simplest shape while still upholding the high standard for predictive accuracy. Subsequently, this simplest member in the acceptable family is presented in the second plot for each regression function. 


Upon execution, the `Interpret_SOFR()` function returns a list, which includes the simplest member of the acceptable family (`simplest_acc_family`), all the locally constant estimates with different complexity (`locally_constant`), as well as their corresponding empirical (`empirical_MSE`) and uncertainty quantification of mean squared errors (`predictive_MSE`):

```{r}
names(SOFR_Interpret)
```















An interesting fact to note is that the simplest member of acceptable family often exhibits a stronger resemblance to the ground truth, especially when the ground truth takes a `stepwise` pattern (see the results above for $\beta_3$). Conversely, $\beta_2$, which exhibits a more gradually varying ground truth (`smooth`), has the simplest acceptable member encompassing a greater number of changing points. This occurs as the model strives to represent the smooth ground truth using locally constant segments. 













# References
